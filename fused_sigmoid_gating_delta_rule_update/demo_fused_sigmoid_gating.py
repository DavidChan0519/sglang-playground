#!/usr/bin/env python3
"""
Fused Sigmoid Gating Delta Rule Update - æ¼”ç¤ºè„šæœ¬

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ PyTorch native å®ç°
"""

import torch
from fused_sigmoid_gating_native_implementation import (
    fused_sigmoid_gating_delta_rule_update_native,
    fused_sigmoid_gating_delta_rule_update_native_optimized,
)


def demo_1_basic_usage():
    """ç¤ºä¾‹ 1: åŸºæœ¬ä½¿ç”¨"""
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 1: åŸºæœ¬ä½¿ç”¨")
    print("=" * 80)

    # é…ç½®
    B, T, H, K, V = 2, 4, 2, 8, 8
    HV = H

    print(f"é…ç½®: Batch={B}, Time={T}, Heads={H}, K_dim={K}, V_dim={V}")

    # åˆ›å»ºè¾“å…¥ï¼ˆéšæœºåˆå§‹åŒ–ï¼‰
    A_log = torch.randn(HV) * 0.1
    a = torch.randn(B, T, HV) * 0.1
    dt_bias = torch.randn(HV) * 0.1
    q = torch.randn(B, T, H, K) * 0.1
    k = torch.randn(B, T, H, K) * 0.1
    v = torch.randn(B, T, HV, V) * 0.1
    b = torch.randn(B, T, HV) * 0.1

    print("\nè¾“å…¥ç»Ÿè®¡:")
    print(f"  q: shape={q.shape}, mean={q.mean():.6f}, std={q.std():.6f}")
    print(f"  k: shape={k.shape}, mean={k.mean():.6f}, std={k.std():.6f}")
    print(f"  v: shape={v.shape}, mean={v.mean():.6f}, std={v.std():.6f}")

    # è°ƒç”¨å‡½æ•°
    out = fused_sigmoid_gating_delta_rule_update_native(
        A_log, a, dt_bias,
        softplus_beta=1.0,
        softplus_threshold=20.0,
        q=q, k=k, v=v, b=b,
        initial_state_source=None,
        initial_state_indices=None,
        scale=None,  # ä½¿ç”¨é»˜è®¤ K^-0.5
        use_qk_l2norm_in_kernel=False,
        cu_seqlens=None,
    )

    print("\nè¾“å‡ºç»Ÿè®¡:")
    print(
        f"  out: shape={out.shape}, mean={out.mean():.6f}, std={out.std():.6f}")
    print("\nâœ… åŸºæœ¬ä½¿ç”¨æˆåŠŸï¼")


def demo_2_with_state():
    """ç¤ºä¾‹ 2: å¸¦çŠ¶æ€ç®¡ç†"""
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 2: å¸¦çŠ¶æ€ç®¡ç†ï¼ˆæ¨¡æ‹Ÿå¤šè½®æ¨ç†ï¼‰")
    print("=" * 80)

    B, T, H, K, V = 2, 4, 2, 8, 8
    HV = H
    num_states = 2  # ä¸ºæ¯ä¸ª batch å‡†å¤‡ä¸€ä¸ªçŠ¶æ€

    print(f"é…ç½®: Batch={B}, Time={T}, num_states={num_states}")

    # åˆ›å»ºçŠ¶æ€æ± 
    state_pool = torch.zeros(num_states, HV, K, V)
    state_indices = torch.arange(B)  # Batch 0 ç”¨çŠ¶æ€ 0ï¼ŒBatch 1 ç”¨çŠ¶æ€ 1

    print("\nç¬¬ 1 è½®æ¨ç†:")

    # åˆ›å»ºè¾“å…¥
    A_log = torch.randn(HV) * 0.1
    a = torch.randn(B, T, HV) * 0.1
    dt_bias = torch.randn(HV) * 0.1
    q = torch.randn(B, T, H, K) * 0.1
    k = torch.randn(B, T, H, K) * 0.1
    v = torch.randn(B, T, HV, V) * 0.1
    b = torch.randn(B, T, HV) * 0.1

    # ç¬¬ä¸€è½®æ¨ç†ï¼ˆåˆå§‹çŠ¶æ€ä¸º 0ï¼‰
    out_1 = fused_sigmoid_gating_delta_rule_update_native(
        A_log, a, dt_bias, 1.0, 20.0,
        q, k, v, b,
        initial_state_source=state_pool,
        initial_state_indices=state_indices,
    )

    print(f"  è¾“å‡º: mean={out_1.mean():.6f}, std={out_1.std():.6f}")
    print(f"  æœ€ç»ˆçŠ¶æ€: mean={state_pool.mean():.6f}, std={state_pool.std():.6f}")

    print("\nç¬¬ 2 è½®æ¨ç†ï¼ˆç»§æ‰¿ä¸Šä¸€è½®çŠ¶æ€ï¼‰:")

    # åˆ›å»ºæ–°è¾“å…¥
    q_2 = torch.randn(B, T, H, K) * 0.1
    k_2 = torch.randn(B, T, H, K) * 0.1
    v_2 = torch.randn(B, T, HV, V) * 0.1
    b_2 = torch.randn(B, T, HV) * 0.1
    a_2 = torch.randn(B, T, HV) * 0.1

    # ç¬¬äºŒè½®æ¨ç†ï¼ˆä½¿ç”¨ä¸Šä¸€è½®çš„æœ€ç»ˆçŠ¶æ€ä½œä¸ºåˆå§‹çŠ¶æ€ï¼‰
    out_2 = fused_sigmoid_gating_delta_rule_update_native(
        A_log, a_2, dt_bias, 1.0, 20.0,
        q_2, k_2, v_2, b_2,
        initial_state_source=state_pool,  # ä½¿ç”¨ä¸Šä¸€è½®æ›´æ–°çš„çŠ¶æ€
        initial_state_indices=state_indices,
    )

    print(f"  è¾“å‡º: mean={out_2.mean():.6f}, std={out_2.std():.6f}")
    print(f"  æœ€ç»ˆçŠ¶æ€: mean={state_pool.mean():.6f}, std={state_pool.std():.6f}")

    print("\nâœ… çŠ¶æ€ç®¡ç†æˆåŠŸï¼Hidden state åœ¨å¤šè½®ä¹‹é—´ä¼ é€’")


def demo_3_optimized_version():
    """ç¤ºä¾‹ 3: ä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬"""
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 3: ä¼˜åŒ–ç‰ˆæœ¬ï¼ˆæ›´å¿«ï¼‰")
    print("=" * 80)

    B, T, H, K, V = 4, 8, 4, 16, 16
    HV = H

    print(f"é…ç½®: Batch={B}, Time={T}, Heads={H}, K_dim={K}, V_dim={V}")

    # åˆ›å»ºè¾“å…¥
    A_log = torch.randn(HV) * 0.1
    a = torch.randn(B, T, HV) * 0.1
    dt_bias = torch.randn(HV) * 0.1
    q = torch.randn(B, T, H, K) * 0.1
    k = torch.randn(B, T, H, K) * 0.1
    v = torch.randn(B, T, HV, V) * 0.1
    b = torch.randn(B, T, HV) * 0.1

    # æµ‹è¯•æ€§èƒ½
    import time

    # åŸºç¡€ç‰ˆæœ¬
    start = time.time()
    out_basic = fused_sigmoid_gating_delta_rule_update_native(
        A_log, a.clone(), dt_bias, 1.0, 20.0,
        q.clone(), k.clone(), v.clone(), b.clone(),
        None, None,
    )
    basic_time = time.time() - start

    # ä¼˜åŒ–ç‰ˆæœ¬
    start = time.time()
    out_optimized = fused_sigmoid_gating_delta_rule_update_native_optimized(
        A_log, a.clone(), dt_bias, 1.0, 20.0,
        q.clone(), k.clone(), v.clone(), b.clone(),
        None, None,
    )
    optimized_time = time.time() - start

    print(f"\næ€§èƒ½å¯¹æ¯”:")
    print(f"  åŸºç¡€ç‰ˆæœ¬: {basic_time*1000:.2f}ms")
    print(f"  ä¼˜åŒ–ç‰ˆæœ¬: {optimized_time*1000:.2f}ms")
    print(f"  åŠ é€Ÿæ¯”: {basic_time / optimized_time:.2f}x")

    # éªŒè¯ç­‰ä»·æ€§
    max_diff = (out_basic - out_optimized).abs().max().item()
    print(f"\nç²¾åº¦éªŒè¯:")
    print(f"  æœ€å¤§å·®å¼‚: {max_diff:.2e}")
    print(f"  ç­‰ä»·æ€§: {'âœ… é€šè¿‡' if max_diff < 1e-6 else 'âŒ å¤±è´¥'}")


def demo_4_with_l2norm():
    """ç¤ºä¾‹ 4: å¸¦ L2 å½’ä¸€åŒ–"""
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 4: Q/K L2 å½’ä¸€åŒ–")
    print("=" * 80)

    B, T, H, K, V = 2, 4, 2, 8, 8
    HV = H

    print(f"é…ç½®: Batch={B}, Time={T}, use_qk_l2norm=True")

    # åˆ›å»ºè¾“å…¥ï¼ˆæ•…æ„ä½¿ç”¨ä¸åŒèŒƒæ•°çš„æ•°æ®ï¼‰
    A_log = torch.randn(HV) * 0.1
    a = torch.randn(B, T, HV) * 0.1
    dt_bias = torch.randn(HV) * 0.1
    q = torch.randn(B, T, H, K) * 2.0  # è¾ƒå¤§çš„èŒƒæ•°
    k = torch.randn(B, T, H, K) * 0.5  # è¾ƒå°çš„èŒƒæ•°
    v = torch.randn(B, T, HV, V) * 0.1
    b = torch.randn(B, T, HV) * 0.1

    print("\nè¾“å…¥ç»Ÿè®¡:")
    print(f"  q èŒƒæ•°: mean={torch.norm(q, dim=-1).mean():.6f}")
    print(f"  k èŒƒæ•°: mean={torch.norm(k, dim=-1).mean():.6f}")

    # ä¸ä½¿ç”¨ L2 å½’ä¸€åŒ–
    out_no_norm = fused_sigmoid_gating_delta_rule_update_native(
        A_log, a.clone(), dt_bias, 1.0, 20.0,
        q.clone(), k.clone(), v.clone(), b.clone(),
        None, None,
        use_qk_l2norm_in_kernel=False,
    )

    # ä½¿ç”¨ L2 å½’ä¸€åŒ–
    out_with_norm = fused_sigmoid_gating_delta_rule_update_native(
        A_log, a.clone(), dt_bias, 1.0, 20.0,
        q.clone(), k.clone(), v.clone(), b.clone(),
        None, None,
        use_qk_l2norm_in_kernel=True,
    )

    print("\nè¾“å‡ºç»Ÿè®¡:")
    print(
        f"  ä¸ä½¿ç”¨ L2 norm: mean={out_no_norm.mean():.6f}, std={out_no_norm.std():.6f}")
    print(
        f"  ä½¿ç”¨ L2 norm:   mean={out_with_norm.mean():.6f}, std={out_with_norm.std():.6f}")
    print(f"  å·®å¼‚: mean={(out_no_norm - out_with_norm).abs().mean():.6f}")

    print("\nâœ… L2 å½’ä¸€åŒ–å½±å“äº†è¾“å‡ºï¼ˆè¿™æ˜¯é¢„æœŸçš„ï¼‰")


def demo_5_understand_algorithm():
    """ç¤ºä¾‹ 5: ç†è§£ç®—æ³•åŸç†"""
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 5: ç†è§£ç®—æ³•åŸç†ï¼ˆå•æ­¥åˆ†æï¼‰")
    print("=" * 80)

    # ç®€åŒ–é…ç½®ï¼ˆå• batchï¼Œå• headï¼Œå•æ—¶é—´æ­¥ï¼‰
    B, T, H, K, V = 1, 1, 1, 4, 4
    HV = H

    print(f"é…ç½®: å•ä¸ªæ ·æœ¬ï¼Œå•ä¸ªæ—¶é—´æ­¥ï¼Œä¾¿äºç†è§£")

    # åˆ›å»ºç®€å•çš„è¾“å…¥
    A_log = torch.tensor([-1.0])  # è¡°å‡å‚æ•°
    a = torch.tensor([[[0.5]]])  # [B, T, HV]
    dt_bias = torch.tensor([0.5])
    q = torch.tensor([[[[1.0, 0.0, 0.0, 0.0]]]])  # [B, T, H, K]
    k = torch.tensor([[[[0.0, 1.0, 0.0, 0.0]]]])  # [B, T, H, K]
    v = torch.tensor([[[[1.0, 2.0, 3.0, 4.0]]]])  # [B, T, HV, V]
    b = torch.tensor([[[0.0]]])  # sigmoid(0) = 0.5

    print("\nè¾“å…¥:")
    print(f"  A_log = {A_log.item():.2f}")
    print(f"  a = {a.squeeze().item():.2f}")
    print(f"  dt_bias = {dt_bias.item():.2f}")
    print(f"  q = {q.squeeze().tolist()}")
    print(f"  k = {k.squeeze().tolist()}")
    print(f"  v = {v.squeeze().tolist()}")
    print(f"  b = {b.squeeze().item():.2f}")

    # æ‰‹åŠ¨è®¡ç®—ï¼ˆæ¨¡æ‹Ÿç®—æ³•æµç¨‹ï¼‰
    print("\nç®—æ³•æ­¥éª¤:")

    # 1. è®¡ç®— g
    import math
    x = a.item() + dt_bias.item()
    softplus_x = math.log(1 + math.exp(x))
    g = -math.exp(A_log.item()) * softplus_x
    print(f"  1. g = -exp({A_log.item():.2f}) * softplus({x:.2f}) = {g:.4f}")

    # 2. è®¡ç®— beta
    beta = 1.0 / (1.0 + math.exp(-b.item()))
    print(f"  2. beta = sigmoid({b.item():.2f}) = {beta:.4f}")

    # 3. åˆå§‹ hidden state
    h = torch.zeros(HV, K, V)
    print(f"  3. åˆå§‹ h = 0")

    # 4. è¡°å‡
    h = h * math.exp(g)
    print(f"  4. h *= exp({g:.4f}) = 0 (ä»ä¸º 0)")

    # 5. Delta rule
    v_adjusted = v.squeeze() - torch.sum(h * k.squeeze()[:, None], dim=0)
    print(f"  5. v_adjusted = v - sum(h * k) = {v_adjusted.tolist()}")

    # 6. Beta gating
    v_adjusted = v_adjusted * beta
    print(f"  6. v_adjusted *= {beta:.4f} = {v_adjusted.tolist()}")

    # 7. æ›´æ–° h
    h = h + k.squeeze()[:, None] * v_adjusted[None, :]
    print(f"  7. h æ›´æ–°å:")
    print(f"     {h.tolist()}")

    # 8. è®¡ç®—è¾“å‡º
    out_manual = torch.sum(h * q.squeeze()[:, None], dim=0)
    print(f"  8. out = sum(h * q) = {out_manual.tolist()}")

    # ä½¿ç”¨å‡½æ•°è®¡ç®—
    out_func = fused_sigmoid_gating_delta_rule_update_native(
        A_log, a, dt_bias, 1.0, 20.0,
        q, k, v, b,
        None, None,
    )

    print(f"\nå‡½æ•°è¾“å‡º: {out_func.squeeze().tolist()}")
    print(f"æ‰‹åŠ¨è®¡ç®—: {out_manual.tolist()}")
    print(f"å·®å¼‚: {(out_func.squeeze() - out_manual).abs().max():.2e}")

    print("\nâœ… æ‰‹åŠ¨è®¡ç®—ä¸å‡½æ•°è¾“å‡ºä¸€è‡´ï¼")


def main():
    """è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
    print("\n" + "â•”" + "=" * 78 + "â•—")
    print("â•‘" + " " * 15 + "Fused Sigmoid Gating Delta Rule Update æ¼”ç¤º" + " " * 20 + "â•‘")
    print("â•š" + "=" * 78 + "â•")

    print(f"\nâœ… PyTorch ç‰ˆæœ¬: {torch.__version__}")
    print(f"âœ… è®¾å¤‡: {'CUDA' if torch.cuda.is_available() else 'CPU'}")

    # è¿è¡Œæ‰€æœ‰æ¼”ç¤º
    demos = [
        demo_1_basic_usage,
        demo_2_with_state,
        demo_3_optimized_version,
        demo_4_with_l2norm,
        demo_5_understand_algorithm,
    ]

    for demo in demos:
        try:
            demo()
        except Exception as e:
            print(f"\nâŒ æ¼”ç¤ºå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    # æ€»ç»“
    print("\n" + "=" * 80)
    print("æ¼”ç¤ºæ€»ç»“")
    print("=" * 80)
    print("âœ… ç¤ºä¾‹ 1: åŸºæœ¬ä½¿ç”¨ - äº†è§£å‡½æ•°è°ƒç”¨æ–¹å¼")
    print("âœ… ç¤ºä¾‹ 2: çŠ¶æ€ç®¡ç† - æ¨¡æ‹Ÿå¤šè½®æ¨ç†")
    print("âœ… ç¤ºä¾‹ 3: ä¼˜åŒ–ç‰ˆæœ¬ - æå‡æ€§èƒ½")
    print("âœ… ç¤ºä¾‹ 4: L2 å½’ä¸€åŒ– - ç†è§£å‚æ•°å½±å“")
    print("âœ… ç¤ºä¾‹ 5: ç®—æ³•åŸç† - æ·±å…¥ç†è§£æ¯ä¸€æ­¥")

    print("\n" + "ğŸ‰ " * 20)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼å¯ä»¥å¼€å§‹ä½¿ç”¨ Native å®ç°äº†")
    print("ğŸ‰ " * 20)

    print("\nğŸ“š æ›´å¤šä¿¡æ¯è¯·æŸ¥çœ‹:")
    print("  - fused_sigmoid_gating_native_implementation.py  (æ ¸å¿ƒå®ç°)")
    print("  - FUSED_SIGMOID_GATING_ANALYSIS.md             (è¯¦ç»†åˆ†æ)")
    print("  - test_fused_sigmoid_gating_native.py          (æµ‹è¯•å¥—ä»¶)")


if __name__ == "__main__":
    main()
